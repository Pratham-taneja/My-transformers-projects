{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers\n",
    "! pip install datasets\n",
    "! pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install accelerate==0.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt install tesseract-ocr\n",
    "! pip install -q pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the model\n",
    "model = \"microsoft/layoutlmv2-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nielsr/docvqa_1200_examples\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = dataset.map(lambda example: {\"question\": example[\"query\"][\"en\"]}, remove_columns=[\"query\"])\n",
    "updated_dataset = updated_dataset.map(\n",
    "    lambda example: {\"answer\": example[\"answers\"][0]}, remove_columns=[\"answer\", \"answers\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = updated_dataset.filter(lambda x: len(x[\"words\"]) + len(x[\"question\"].split()) < 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing pre-existing boxes and words\n",
    "\n",
    "updated_dataset = updated_dataset.remove_columns(\"words\")\n",
    "updated_dataset = updated_dataset.remove_columns(\"bounding_boxes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset[\"train\"][11][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading auto dataa processor\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing the data using auto processor\n",
    "image_processor = processor.image_processor\n",
    "\n",
    "\n",
    "def get_ocr_words_and_boxes(examples):\n",
    "    images = [image.convert(\"RGB\") for image in examples[\"image\"]]\n",
    "    encoded_inputs = image_processor(images)\n",
    "\n",
    "    examples[\"image\"] = encoded_inputs.pixel_values\n",
    "    examples[\"words\"] = encoded_inputs.words\n",
    "    examples[\"boxes\"] = encoded_inputs.boxes\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset with ocr\n",
    "dataset_with_ocr = updated_dataset.map(get_ocr_words_and_boxes, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading in tokenizer\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating indices for the answers\n",
    "def subfinder(words_list, answer_list):\n",
    "    matches = []\n",
    "    start_indices = []\n",
    "    end_indices = []\n",
    "    for idx, i in enumerate(range(len(words_list))):\n",
    "        if words_list[i] == answer_list[0] and words_list[i : i + len(answer_list)] == answer_list:\n",
    "            matches.append(answer_list)\n",
    "            start_indices.append(idx)\n",
    "            end_indices.append(idx + len(answer_list) - 1)\n",
    "    if matches:\n",
    "        return matches[0], start_indices[0], end_indices[0]\n",
    "    else:\n",
    "        return None, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset_with_ocr[\"train\"][1]\n",
    "words = [word.lower() for word in example[\"words\"]]\n",
    "match, word_idx_start, word_idx_end = subfinder(words, example[\"answer\"].lower().split())\n",
    "print(\"Question: \", example[\"question\"])\n",
    "print(\"Words:\", words)\n",
    "print(\"Answer: \", example[\"answer\"])\n",
    "print(\"start_index\", word_idx_start)\n",
    "print(\"end_index\", word_idx_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(example[\"question\"], example[\"words\"], example[\"boxes\"])\n",
    "tokenizer.decode(encoding[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating the encoded dataset with the indices of the answers\n",
    "def encode_dataset(examples, max_length=512):\n",
    "    questions = examples[\"question\"]\n",
    "    words = examples[\"words\"]\n",
    "    boxes = examples[\"boxes\"]\n",
    "    answers = examples[\"answer\"]\n",
    "\n",
    "    # encode the batch of examples and initialize the start_positions and end_positions\n",
    "    encoding = tokenizer(questions, words, boxes, max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # loop through the examples in the batch\n",
    "    for i in range(len(questions)):\n",
    "        cls_index = encoding[\"input_ids\"][i].index(tokenizer.cls_token_id)\n",
    "\n",
    "        # find the position of the answer in example's words\n",
    "        words_example = [word.lower() for word in words[i]]\n",
    "        answer = answers[i]\n",
    "        match, word_idx_start, word_idx_end = subfinder(words_example, answer.lower().split())\n",
    "\n",
    "        if match:\n",
    "            # if match is found, use `token_type_ids` to find where words start in the encoding\n",
    "            token_type_ids = encoding[\"token_type_ids\"][i]\n",
    "            token_start_index = 0\n",
    "            while token_type_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(encoding[\"input_ids\"][i]) - 1\n",
    "            while token_type_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            word_ids = encoding.word_ids(i)[token_start_index : token_end_index + 1]\n",
    "            start_position = cls_index\n",
    "            end_position = cls_index\n",
    "\n",
    "            # loop over word_ids and increase `token_start_index` until it matches the answer position in words\n",
    "            # once it matches, save the `token_start_index` as the `start_position` of the answer in the encoding\n",
    "            for id in word_ids:\n",
    "                if id == word_idx_start:\n",
    "                    start_position = token_start_index\n",
    "                else:\n",
    "                    token_start_index += 1\n",
    "\n",
    "            # similarly loop over `word_ids` starting from the end to find the `end_position` of the answer\n",
    "            for id in word_ids[::-1]:\n",
    "                if id == word_idx_end:\n",
    "                    end_position = token_end_index\n",
    "                else:\n",
    "                    token_end_index -= 1\n",
    "\n",
    "            start_positions.append(start_position)\n",
    "            end_positions.append(end_position)\n",
    "\n",
    "        else:\n",
    "            start_positions.append(cls_index)\n",
    "            end_positions.append(cls_index)\n",
    "\n",
    "    encoding[\"image\"] = examples[\"image\"]\n",
    "    encoding[\"start_positions\"] = start_positions\n",
    "    encoding[\"end_positions\"] = end_positions\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## spliting into trainig and testing dataset\n",
    "encoded_train_dataset = dataset_with_ocr[\"train\"].map(\n",
    "    encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr[\"train\"].column_names\n",
    ")\n",
    "encoded_test_dataset = dataset_with_ocr[\"test\"].map(\n",
    "    encode_dataset, batched=True, batch_size=2, remove_columns=dataset_with_ocr[\"test\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForDocumentQuestionAnswering\n",
    "\n",
    "model = AutoModelForDocumentQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"outputs\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_test_dataset,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
